{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Prédiction de l'action du joueur de Tennis"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Lire les donées**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T17:32:10.883559Z","iopub.status.busy":"2023-05-01T17:32:10.883049Z","iopub.status.idle":"2023-05-01T17:32:11.020036Z","shell.execute_reply":"2023-05-01T17:32:11.018813Z","shell.execute_reply.started":"2023-05-01T17:32:10.883521Z"},"trusted":true},"outputs":[],"source":["# Lecture des données\n","\n","import numpy as np\n","from PIL import Image \n","import glob\n","import cv2\n","\n","# Label de la sortie\n","# 0 : cd\n","# 1 : rv\n","# 2 : sm\n","# 3 : sv\n","\n","# 0 : rv\n","# 1 : rv_slice\n","# 2 : rv_vol\n","# 3 : rv_2_main\n","# 4 : cd_flat\n","# 5 : cd_OS\n","# 6 : cd_slice\n","# 7 : cd_vol\n","# 8 : sv_flat \n","# 9 : sv_kick\n","# 10: sv_slice\n","# 11: sm\n","\n","action_size = 12\n","data_size = 150\n","frame_size = 15\n","action_list = [0, 4, 8]\n","X = []\n","X_cnn = []\n","y = []\n","for k in action_list: # range(action_size): # chaque action\n","    for i in range(data_size): # chaque vidéo est une données\n","        D = []\n","        I = cv2.imread(\"F:/Tennis/prediction/frame_0.jpg\")\n","        I = cv2.resize(I, (16, 12))\n","        for image in glob.glob(f\"F:/Tennis/prediction/ac{k}/vid ({i})/*.jpg\"): # for j in range(frame_size): # chaque frame est une variable, 16*12 * 15 = 2880\n","            # img = PIL.Image.open(f\"F:/Tennis/prediction/ac{k}/vid ({i})/frame_0{j}.jpg\").convert(\"L\")\n","            img = Image.open(image).convert(\"L\")\n","            img = img.resize((16, 12))\n","            imgarr = np.array(img)\n","            img_row = imgarr.reshape(-1) # transformer en ligne\n","            D = np.append(D, img_row)\n","            img = cv2.imread(image) # (longueur, hauteur, channel)\n","            img = cv2.resize(img, (16, 12)) # (int(img.shape[0] / 40), int(img.shape[1] / 40)))\n","            I = np.hstack((I, img))\n","            # image = np.vstack((img1, img2)) # concaténation verticale des frames\n","            # image = np.hstack((img1, img2)) # concaténation horizontale des frames\n","        X.append(D)\n","        X_cnn.append(I)\n","        y.append(k/4)\n","X = np.array(X)\n","X_cnn = np.array(X_cnn)\n","y = np.array(y)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["450\n","(450, 2880) (2880,) 0.0\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.float64'>\n","450\n","(450, 12, 256, 3) (12, 256, 3) (256, 3)\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","450\n","(450,) 0.0\n","<class 'numpy.ndarray'> <class 'numpy.float64'>\n"]}],"source":["# Visualisation des données\n","print(len(X))\n","print(X.shape, X[20].shape, X[21][2833])\n","print(type(X), type(X[0]), type(X[0][0]))\n","print(len(X_cnn))\n","print(X_cnn.shape, X_cnn[20].shape, X_cnn[21][6].shape)\n","print(type(X_cnn), type(X_cnn[0]), type(X_cnn[0][0]))\n","print(len(y))\n","print(y.shape, y[101])\n","print(type(y), type(y[101]))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(15, 2880)\n","(15, 12, 256, 3)\n"]}],"source":["# Préparation de l'ensemble de test\n","import numpy as np\n","import PIL\n","from PIL import Image \n","test_size = 15\n","frame_size = 15\n","X_test = []\n","X_test_cnn = []\n","# [0 0 0 0 0 4 4 4 4 4 8 8 8 8 8]\n","\n","for i in range(test_size): # chaque vidéo est une données\n","        T = []\n","        I = cv2.imread(\"F:/Tennis/prediction/frame_0.jpg\")\n","        I = cv2.resize(I, (16, 12))\n","        for image in glob.glob(f\"F:/Tennis/prediction/test/test{i}/*.jpg\"): # for j in range(frame_size): # chaque frame est une variable, 16*12 * 15 = 2880\n","            # img = PIL.Image.open(f\"F:/Tennis/prediction/test/test{i}/frame_{j}.jpg\").convert(\"L\")\n","            img = Image.open(image).convert(\"L\")\n","            img = img.resize((16, 12))\n","            imgarr = np.array(img)\n","            img_row = imgarr.reshape(-1) # transformer en ligne\n","            T = np.append(T, img_row)\n","            img = cv2.imread(image) # (longueur, hauteur, channel)\n","            img = cv2.resize(img, (16, 12)) # (int(img.shape[0] / 40), int(img.shape[1] / 40)))\n","            I = np.hstack((I, img))\n","        X_test.append(T)\n","        X_test_cnn.append(I)\n","X_test = np.array(X_test)\n","X_test_cnn = np.array(X_test_cnn)\n","print(X_test.shape)\n","print(X_test_cnn.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(480, 640, 3)\n","(16, 12, 3)\n"]}],"source":["# Test de la compression des images\n","import cv2\n","\n","img = cv2.imread('frame_0.jpg')\n","print(img.shape)\n","#x, y = img.shape[0:2]\n","# cv2.imshow('OriginalPicture', img)\n"," \n","img_test1 = cv2.resize(img, (int(img.shape[0] / 40), int(img.shape[1] / 40)))\n","print(img_test1.shape)\n","# cv2.imshow('resize0', img_test1)\n","\n","img = PIL.Image.open(\"F:/Tennis/prediction/frame_0.jpg\").convert(\"L\") # L = R * 299/1000 + G * 587/1000 + B * 114/1000 # (\"RGB\")\n","img = img.resize((20, 20))\n","img = img.save(\"F:/Tennis/prediction/frame_0_test.jpg\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**K-means**"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# from sklearn.cluster import KMeans\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n","# kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X, y)\n","# kmeans.labels_\n","# kmeans.predict([[0, 0], [12, 3]])\n","# kmeans.cluster_centers_\n","\n","# plt.scatter(X, y, c=kmeans.labels_)\n","# plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Arbre de décision**"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# from sklearn.datasets import load_iris\n","# from sklearn import tree\n","\n","# X, y = X.values, y.values\n","# clf = tree.DecisionTreeClassifier()\n","# clf = clf.fit(X, y)\n","\n","# tree.plot_tree(clf)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Réseaux de neurones**"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T17:33:00.198694Z","iopub.status.busy":"2023-05-01T17:33:00.198055Z","iopub.status.idle":"2023-05-01T17:33:13.210244Z","shell.execute_reply":"2023-05-01T17:33:13.209050Z","shell.execute_reply.started":"2023-05-01T17:33:00.198654Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_13 (Dense)            (None, 16)                46096     \n","                                                                 \n"," dense_14 (Dense)            (None, 32)                544       \n","                                                                 \n"," dense_15 (Dense)            (None, 64)                2112      \n","                                                                 \n"," dense_16 (Dense)            (None, 128)               8320      \n","                                                                 \n"," dense_17 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 57,459\n","Trainable params: 57,459\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Construction du model avec tensorflow\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import tensorflow as tf\n","\n","model = Sequential(\n","    [               \n","        tf.keras.Input(shape = 2880), # 16*12 * 15 = 2880\n","        Dense(units=16, activation=\"relu\"),\n","        Dense(units=32, activation=\"relu\"),\n","        Dense(units=64, activation=\"sigmoid\"),\n","        Dense(units=128, activation=\"relu\"),\n","        Dense(units=3, activation=\"softmax\"),\n","    ]\n",")          \n","model.summary()\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T17:33:13.225244Z","iopub.status.busy":"2023-05-01T17:33:13.224682Z","iopub.status.idle":"2023-05-01T17:34:13.911133Z","shell.execute_reply":"2023-05-01T17:34:13.910061Z","shell.execute_reply.started":"2023-05-01T17:33:13.225203Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","15/15 [==============================] - 1s 1ms/step - loss: 1.1244 - accuracy: 0.3378\n","Epoch 2/50\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0938 - accuracy: 0.3622\n","Epoch 3/50\n","15/15 [==============================] - 0s 2ms/step - loss: 1.0531 - accuracy: 0.4400\n","Epoch 4/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9624 - accuracy: 0.5844\n","Epoch 5/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.8605 - accuracy: 0.6422\n","Epoch 6/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.7511\n","Epoch 7/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.7800\n","Epoch 8/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.8289\n","Epoch 9/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7689\n","Epoch 10/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.8200\n","Epoch 11/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8422\n","Epoch 12/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.3053 - accuracy: 0.8844\n","Epoch 13/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9178\n","Epoch 14/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9400\n","Epoch 15/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9289\n","Epoch 16/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9533\n","Epoch 17/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9511\n","Epoch 18/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9556\n","Epoch 19/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9244\n","Epoch 20/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9378\n","Epoch 21/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9533\n","Epoch 22/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.9400\n","Epoch 23/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9778\n","Epoch 24/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9378\n","Epoch 25/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9467\n","Epoch 26/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9667\n","Epoch 27/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9822\n","Epoch 28/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9800\n","Epoch 29/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9822\n","Epoch 30/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9933\n","Epoch 31/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9956\n","Epoch 32/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9844\n","Epoch 33/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9867\n","Epoch 34/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9933\n","Epoch 35/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9956\n","Epoch 36/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9978\n","Epoch 37/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 1.0000\n","Epoch 38/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 39/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 40/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 41/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 42/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 43/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 44/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 45/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 46/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 47/50\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 48/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 49/50\n","15/15 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 50/50\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","1/1 [==============================] - 0s 68ms/step\n","[[9.2463851e-01 7.3719718e-02 1.6418025e-03]\n"," [1.2788271e-03 1.8862196e-05 9.9870229e-01]\n"," [9.8672915e-01 4.8618880e-04 1.2784662e-02]\n"," [9.9953711e-01 2.5320298e-04 2.0965196e-04]\n"," [9.9902630e-01 8.4802060e-04 1.2567648e-04]\n"," [6.2773115e-04 3.1950543e-04 9.9905270e-01]\n"," [1.8319566e-04 9.9904281e-01 7.7405758e-04]\n"," [2.3449879e-04 9.9948585e-01 2.7966412e-04]\n"," [1.4042130e-04 9.9971348e-01 1.4612816e-04]\n"," [2.1323345e-05 9.9996817e-01 1.0442379e-05]\n"," [2.3367335e-03 7.6866962e-02 9.2079628e-01]\n"," [2.0640538e-05 5.4507163e-05 9.9992490e-01]\n"," [6.6186685e-06 4.4012140e-05 9.9994934e-01]\n"," [6.2312065e-06 4.3009106e-05 9.9995077e-01]\n"," [8.9945070e-06 5.3996031e-05 9.9993706e-01]]\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import tensorflow as tf\n","\n","model.compile(\n","    #optimizer = 'RMSprop', loss = 'categorical_crossentropy', metrics = ['acc']\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # 'sparse_categorical_crossentropy',\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), # 'Adam',\n","    metrics=['accuracy']\n",")\n","\n","history = model.fit(\n","    X, y,\n","    epochs = 50,\n","    # batch_size = 32 # données transmises pour une session\n",")\n","\n","prediction = model.predict(X_test) # np.expand_dims(X_test, axis = 1)\n","# prediction_p = tf.nn.softmax(prediction)\n","# yhat = np.argmax(prediction)\n","print (prediction)\n","\n","# Softmax\n","# def softmax(z):  \n","#     ez = np.exp(z)\n","#     a = ez/np.sum(ez)\n","#     return a\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8]\n","# [0, 8, 0, 0, 0, 8, 4, 4, 4, 4, 8, 8, 8, 8, 8]\n","# 13/15"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Réseau neuronal convolutif**"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, 10, 254, 32)       896       \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 10, 254, 32)      128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 5, 127, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 5, 127, 32)        0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 3, 125, 64)        18496     \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 3, 125, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 1, 62, 64)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_4 (Dropout)         (None, 1, 62, 64)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 3968)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 11907     \n","                                                                 \n","=================================================================\n","Total params: 31,683\n","Trainable params: 31,491\n","Non-trainable params: 192\n","_________________________________________________________________\n"]}],"source":["# contruction du modèle\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","\n","model_cnn = Sequential(\n","    [\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(12, 256, 3)), # kernel_size, strides, padding = 'same'\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","        \n","        Conv2D(64, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","        \n","        # Conv2D(128, (3, 3), activation='relu'),\n","        # BatchNormalization(),\n","        # MaxPooling2D(pool_size=(2, 2)),\n","        # Dropout(0.25),\n","        \n","        Flatten(),\n","        # Dense(512, activation='relu'),\n","        # BatchNormalization(),\n","        # Dropout(0.5),\n","        Dense(3, activation='softmax')\n","    ]\n",")            \n","model_cnn.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # loss pour one-hot coding\n","model_cnn.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","15/15 [==============================] - 1s 48ms/step - loss: 3.1871 - accuracy: 0.4422\n","Epoch 2/50\n","15/15 [==============================] - 1s 48ms/step - loss: 1.0373 - accuracy: 0.6978\n","Epoch 3/50\n","15/15 [==============================] - 1s 48ms/step - loss: 1.1371 - accuracy: 0.6644\n","Epoch 4/50\n","15/15 [==============================] - 1s 47ms/step - loss: 0.8599 - accuracy: 0.7422\n","Epoch 5/50\n","15/15 [==============================] - 1s 46ms/step - loss: 0.4269 - accuracy: 0.8444\n","Epoch 6/50\n","15/15 [==============================] - 1s 50ms/step - loss: 0.4851 - accuracy: 0.8200\n","Epoch 7/50\n","15/15 [==============================] - 1s 49ms/step - loss: 0.3971 - accuracy: 0.8689\n","Epoch 8/50\n","15/15 [==============================] - 1s 51ms/step - loss: 0.3078 - accuracy: 0.8889\n","Epoch 9/50\n","15/15 [==============================] - 1s 52ms/step - loss: 0.4316 - accuracy: 0.8511\n","Epoch 10/50\n","15/15 [==============================] - 1s 50ms/step - loss: 0.2784 - accuracy: 0.9111\n","Epoch 11/50\n","15/15 [==============================] - 1s 45ms/step - loss: 0.2453 - accuracy: 0.9089\n","Epoch 12/50\n","15/15 [==============================] - 1s 43ms/step - loss: 0.1827 - accuracy: 0.9244\n","Epoch 13/50\n","15/15 [==============================] - 1s 45ms/step - loss: 0.1316 - accuracy: 0.9600\n","Epoch 14/50\n","15/15 [==============================] - 1s 46ms/step - loss: 0.1456 - accuracy: 0.9533\n","Epoch 15/50\n","15/15 [==============================] - 1s 44ms/step - loss: 0.0851 - accuracy: 0.9778\n","Epoch 16/50\n","15/15 [==============================] - 1s 47ms/step - loss: 0.1165 - accuracy: 0.9467\n","Epoch 17/50\n","15/15 [==============================] - 1s 47ms/step - loss: 0.0934 - accuracy: 0.9689\n","Epoch 18/50\n","15/15 [==============================] - 1s 44ms/step - loss: 0.1592 - accuracy: 0.9400\n","Epoch 19/50\n","15/15 [==============================] - 1s 44ms/step - loss: 0.0718 - accuracy: 0.9733\n","Epoch 20/50\n","15/15 [==============================] - 1s 44ms/step - loss: 0.0813 - accuracy: 0.9689\n","Epoch 21/50\n","15/15 [==============================] - 1s 43ms/step - loss: 0.0347 - accuracy: 0.9844\n","Epoch 22/50\n","15/15 [==============================] - 1s 45ms/step - loss: 0.1343 - accuracy: 0.9556\n","Epoch 23/50\n","15/15 [==============================] - 1s 48ms/step - loss: 0.0410 - accuracy: 0.9911\n","Epoch 24/50\n","15/15 [==============================] - 1s 59ms/step - loss: 0.0655 - accuracy: 0.9822\n","Epoch 25/50\n","15/15 [==============================] - 1s 50ms/step - loss: 0.0529 - accuracy: 0.9778\n","Epoch 26/50\n","15/15 [==============================] - 1s 54ms/step - loss: 0.0402 - accuracy: 0.9844\n","Epoch 27/50\n","15/15 [==============================] - 1s 59ms/step - loss: 0.0537 - accuracy: 0.9844\n","Epoch 28/50\n","15/15 [==============================] - 1s 52ms/step - loss: 0.0579 - accuracy: 0.9800\n","Epoch 29/50\n","15/15 [==============================] - 1s 51ms/step - loss: 0.0430 - accuracy: 0.9844\n","Epoch 30/50\n","15/15 [==============================] - 1s 50ms/step - loss: 0.0346 - accuracy: 0.9822\n","Epoch 31/50\n","15/15 [==============================] - 1s 63ms/step - loss: 0.0209 - accuracy: 0.9933\n","Epoch 32/50\n","15/15 [==============================] - 1s 67ms/step - loss: 0.0227 - accuracy: 0.9933\n","Epoch 33/50\n","15/15 [==============================] - 1s 63ms/step - loss: 0.0858 - accuracy: 0.9689\n","Epoch 34/50\n","15/15 [==============================] - 1s 54ms/step - loss: 0.0347 - accuracy: 0.9867\n","Epoch 35/50\n","15/15 [==============================] - 1s 57ms/step - loss: 0.0339 - accuracy: 0.9911\n","Epoch 36/50\n","15/15 [==============================] - 1s 53ms/step - loss: 0.0088 - accuracy: 0.9978\n","Epoch 37/50\n","15/15 [==============================] - 1s 52ms/step - loss: 0.0169 - accuracy: 0.9956\n","Epoch 38/50\n","15/15 [==============================] - 1s 51ms/step - loss: 0.0309 - accuracy: 0.9889\n","Epoch 39/50\n","15/15 [==============================] - 1s 62ms/step - loss: 0.0339 - accuracy: 0.9911\n","Epoch 40/50\n","15/15 [==============================] - 1s 58ms/step - loss: 0.0095 - accuracy: 1.0000\n","Epoch 41/50\n","15/15 [==============================] - 1s 52ms/step - loss: 0.0233 - accuracy: 0.9911\n","Epoch 42/50\n","15/15 [==============================] - 1s 47ms/step - loss: 0.0303 - accuracy: 0.9889\n","Epoch 43/50\n","15/15 [==============================] - 1s 47ms/step - loss: 0.0301 - accuracy: 0.9889\n","Epoch 44/50\n","15/15 [==============================] - 1s 50ms/step - loss: 0.0162 - accuracy: 0.9911\n","Epoch 45/50\n","15/15 [==============================] - 1s 49ms/step - loss: 0.0063 - accuracy: 1.0000\n","Epoch 46/50\n","15/15 [==============================] - 1s 48ms/step - loss: 0.0444 - accuracy: 0.9911\n","Epoch 47/50\n","15/15 [==============================] - 1s 50ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 48/50\n","15/15 [==============================] - 1s 43ms/step - loss: 0.0394 - accuracy: 0.9911\n","Epoch 49/50\n","15/15 [==============================] - 1s 43ms/step - loss: 0.0077 - accuracy: 0.9978\n","Epoch 50/50\n","15/15 [==============================] - 1s 42ms/step - loss: 0.0193 - accuracy: 0.9978\n"]}],"source":["import tensorflow as tf\n","history = model_cnn.fit(\n","    X_cnn, tf.keras.utils.to_categorical(y, 3), # one-hot coding\n","    epochs = 50,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 134ms/step\n","[[2.69260444e-02 9.73071158e-01 2.84077146e-06]\n"," [8.38717043e-01 1.59975812e-01 1.30718702e-03]\n"," [1.00000000e+00 6.25001340e-09 1.25824329e-09]\n"," [9.67974782e-01 3.20112333e-02 1.39610720e-05]\n"," [9.24357176e-01 7.56428689e-02 1.05627116e-08]\n"," [1.59981484e-09 9.99574721e-01 4.25284758e-04]\n"," [1.59956102e-08 9.99999166e-01 8.86341240e-07]\n"," [1.35899669e-09 1.00000000e+00 1.28263911e-09]\n"," [9.04301387e-14 1.00000000e+00 2.76226642e-09]\n"," [7.44924109e-05 9.99925494e-01 4.96791275e-09]\n"," [5.60752405e-08 3.00664844e-08 9.99999881e-01]\n"," [1.19550961e-07 2.41216696e-07 9.99999642e-01]\n"," [3.37134889e-15 3.43483020e-10 1.00000000e+00]\n"," [2.14642595e-10 2.08238829e-10 1.00000000e+00]\n"," [1.01106154e-16 2.72035663e-07 9.99999762e-01]]\n"]}],"source":["prediction = model_cnn.predict(X_test_cnn)\n","print(prediction)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8]\n","# [4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8]\n","# 13/15"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# N.B: Squelette, confusion, position"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:48:30.442267Z","iopub.status.busy":"2023-05-01T19:48:30.441422Z","iopub.status.idle":"2023-05-01T19:48:30.450620Z","shell.execute_reply":"2023-05-01T19:48:30.449466Z","shell.execute_reply.started":"2023-05-01T19:48:30.442224Z"},"trusted":true},"outputs":[],"source":["# Modèle général pour tester les paramètres\n","\n","# def neural_network(num_layer, units, learning_rate=0.01):\n","#     \"\"\"\n","#     Parameters\n","#     ----------\n","#     num_layer       : int\n","#                     number of layers\n","#     units           : list\n","#                     number of units in each layer\n","#     learning_rate   : float\n","#                     learning rate of the optimizer of the model\n","#     \"\"\"\n","#     if (len(units) != num_layer):\n","#         raise ValueError(\"Number of list of units must be equal to number of layers\")\n","#     model = Sequential()\n","#     model.add(Dense(units=units[0], input_dim=X_train.shape[1], activation=\"relu\"))\n","#     for i in range(1, num_layer-1):\n","#         model.add(Dense(units=units[i], activation=\"relu\"))\n","#     model.add(Dense(units=1, activation=\"linear\"))\n","#     model.compile(\n","#         loss=tf.keras.losses.MeanAbsoluteError(),\n","#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","#         metrics=[tf.keras.metrics.MeanAbsoluteError()]\n","#     )\n","#     return model"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:48:32.720192Z","iopub.status.busy":"2023-05-01T19:48:32.719109Z","iopub.status.idle":"2023-05-01T19:48:32.728809Z","shell.execute_reply":"2023-05-01T19:48:32.727670Z","shell.execute_reply.started":"2023-05-01T19:48:32.720135Z"},"trusted":true},"outputs":[],"source":["# Evaluation des modèle\n","\n","# histories_neural_network = []\n","# def neural_network_score(num_layer, units, learning_rate=[0.001, 0.01, 0.1]):\n","#     \"\"\"\n","#     Parameters\n","#     ----------\n","#     num_layer       : int\n","#                     number of layers\n","#     units           : list\n","#                     number of units in each layer\n","#     learning_rate   : list\n","#                     learning rate of the optimizer of the model\n","#     \"\"\"\n","#     if (len(units) != num_layer):\n","#         raise ValueError('Le nombre de couches doit être égale à la taille de la liste des neurones')\n","#     for i in range(len(learning_rate)):\n","#         model = neural_network(num_layer, units, learning_rate=learning_rate[i])\n","#         model.save(f\"neural_network_model_{i}.h5\")\n","#         history = model.fit(\n","#             X_train, y_train,\n","#             epochs=50,\n","#             batch_size=50,\n","#             validation_split=0.2\n","#         )\n","#         histories_neural_network.append(history)\n","#         y_pred = model.predict(X_test)\n","#         y_pred = np.reshape(y_pred, (y_pred.shape[0],))\n","#         print(f'TEST - R2 score avec le taux {learning_rate[i]} : {r2_score(y_test_numpy, y_pred)}')\n","#         print(f'TEST - MAE score avec le taux {learning_rate[i]} : {history.history[\"val_loss\"][-1]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:48:35.578176Z","iopub.status.busy":"2023-05-01T19:48:35.577549Z","iopub.status.idle":"2023-05-01T19:51:53.617320Z","shell.execute_reply":"2023-05-01T19:51:53.616033Z","shell.execute_reply.started":"2023-05-01T19:48:35.578139Z"},"trusted":true},"outputs":[],"source":["# Entraînement des différents modèles\n","\n","# num_layer = 4\n","# units = [128, 256, 256, 1]\n","# neural_network_score(num_layer, units)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:51:53.620030Z","iopub.status.busy":"2023-05-01T19:51:53.619615Z","iopub.status.idle":"2023-05-01T19:51:53.908437Z","shell.execute_reply":"2023-05-01T19:51:53.907328Z","shell.execute_reply.started":"2023-05-01T19:51:53.619967Z"},"trusted":true},"outputs":[],"source":["#Visualiser les traces\n","\n","# from sklearn.metrics import r2_score\n","# plt.plot(histories_neural_network[0].history['val_loss'])\n","# plt.plot(histories_neural_network[1].history['val_loss'])\n","# plt.plot(histories_neural_network[2].history['val_loss'])\n","# plt.title('Model loss')  \n","# plt.ylabel('Val Loss')  \n","# plt.xlabel('Epoch')  \n","# plt.legend(['taux = 0.001', 'taux = 0.01', 'taux = 0.1'], loc='upper right')  \n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:52:32.649675Z","iopub.status.busy":"2023-05-01T19:52:32.649288Z","iopub.status.idle":"2023-05-01T19:52:33.255224Z","shell.execute_reply":"2023-05-01T19:52:33.254240Z","shell.execute_reply.started":"2023-05-01T19:52:32.649642Z"},"trusted":true},"outputs":[],"source":["# Test de la performance\n","#from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","#from math import sqrt\n","\n","# X_test_numpy = np.array(X_test)\n","# y_test_numpy = np.array(y_test)\n","# y_pred = model.predict(X_test_numpy)\n","# y_pred = np.reshape(y_pred, (y_pred.shape[0],))\n","# plt.scatter(y_test, y_pred, color=\"b\")\n","# plt.plot(y_test, y_test, color=\"r\")\n","# r2_nn = r2_score(y_test_numpy, y_pred)\n","# print('TEST - R2 score - Réseau de neurones: ', r2_nn)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
