{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Prédiction de l'action du joueur de Tennis"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Lire les donées**"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T17:32:10.883559Z","iopub.status.busy":"2023-05-01T17:32:10.883049Z","iopub.status.idle":"2023-05-01T17:32:11.020036Z","shell.execute_reply":"2023-05-01T17:32:11.018813Z","shell.execute_reply.started":"2023-05-01T17:32:10.883521Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["450\n","(450, 2880) (2880,) 0.0\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.float64'>\n","450\n","(450, 12, 256, 3) (12, 256, 3) (256, 3)\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","450\n","(450,) 0.0\n","<class 'numpy.ndarray'> <class 'numpy.float64'>\n"]}],"source":["# Lecture des données\n","\n","import numpy as np\n","import PIL\n","from PIL import Image \n","import glob\n","import cv2\n","\n","# Label de la sortie\n","# 0 : cd\n","# 1 : rv\n","# 2 : sm\n","# 3 : sv\n","\n","# 0 : rv\n","# 1 : rv_slice\n","# 2 : rv_vol\n","# 3 : rv_2_main\n","# 4 : cd_flat\n","# 5 : cd_OS\n","# 6 : cd_slice\n","# 7 : cd_vol\n","# 8 : sv_flat \n","# 9 : sv_kick\n","# 10: sv_slice\n","# 11: sm\n","\n","action_size = 12\n","data_size = 150\n","frame_size = 15\n","action_list = [0, 4, 8]\n","X = []\n","X_cnn = []\n","y = []\n","for k in action_list: # range(action_size): # chaque action\n","    for i in range(data_size): # chaque vidéo est une données\n","        D = []\n","        I = cv2.imread(\"F:/Tennis/prediction/frame_0.jpg\")\n","        I = cv2.resize(I, (16, 12))\n","        for image in glob.glob(f\"F:/Tennis/prediction/ac{k}/vid ({i})/*.jpg\"): # for j in range(frame_size): # chaque frame est une variable, 16*12 * 15 = 2880\n","            # img = PIL.Image.open(f\"F:/Tennis/prediction/ac{k}/vid ({i})/frame_0{j}.jpg\").convert(\"L\")\n","            img = Image.open(image).convert(\"L\")\n","            img = img.resize((16, 12))\n","            imgarr = np.array(img)\n","            img_row = imgarr.reshape(-1) # transformer en ligne\n","            D = np.append(D, img_row)\n","            img = cv2.imread(image) # (longueur, hauteur, channel)\n","            img = cv2.resize(img, (16, 12)) # (int(img.shape[0] / 40), int(img.shape[1] / 40)))\n","            I = np.hstack((I, img))\n","            # image = np.vstack((img1, img2)) # concaténation verticale des frames\n","            # image = np.hstack((img1, img2)) # concaténation horizontale des frames\n","        X.append(D)\n","        X_cnn.append(I)\n","        y.append(k/4)\n","X = np.array(X)\n","X_cnn = np.array(X_cnn)\n","y = np.array(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualisation des données\n","print(len(X))\n","print(X.shape, X[20].shape, X[21][2833])\n","print(type(X), type(X[0]), type(X[0][0]))\n","print(len(X_cnn))\n","print(X_cnn.shape, X_cnn[20].shape, X_cnn[21][6].shape)\n","print(type(X_cnn), type(X_cnn[0]), type(X_cnn[0][0]))\n","print(len(y))\n","print(y.shape, y[101])\n","print(type(y), type(y[101]))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(15, 2880)\n","(15, 12, 256, 3)\n"]}],"source":["# Préparation de l'ensemble de test\n","import numpy as np\n","import PIL\n","from PIL import Image \n","test_size = 15\n","frame_size = 15\n","X_test = []\n","X_test_cnn = []\n","# [0 0 0 0 0 4 4 4 4 4 8 8 8 8 8]\n","\n","for i in range(test_size): # chaque vidéo est une données\n","        T = []\n","        I = cv2.imread(\"F:/Tennis/prediction/frame_0.jpg\")\n","        I = cv2.resize(I, (16, 12))\n","        for image in glob.glob(f\"F:/Tennis/prediction/test/test{i}/*.jpg\"): # for j in range(frame_size): # chaque frame est une variable, 16*12 * 15 = 2880\n","            # img = PIL.Image.open(f\"F:/Tennis/prediction/test/test{i}/frame_{j}.jpg\").convert(\"L\")\n","            img = Image.open(image).convert(\"L\")\n","            img = img.resize((16, 12))\n","            imgarr = np.array(img)\n","            img_row = imgarr.reshape(-1) # transformer en ligne\n","            T = np.append(T, img_row)\n","            img = cv2.imread(image) # (longueur, hauteur, channel)\n","            img = cv2.resize(img, (16, 12)) # (int(img.shape[0] / 40), int(img.shape[1] / 40)))\n","            I = np.hstack((I, img))\n","        X_test.append(T)\n","        X_test_cnn.append(I)\n","X_test = np.array(X_test)\n","X_test_cnn = np.array(X_test_cnn)\n","print(X_test.shape)\n","print(X_test_cnn.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(480, 640, 3)\n","(16, 12, 3)\n"]}],"source":["# Test de la compression des images\n","import cv2\n","\n","img = cv2.imread('frame_0.jpg')\n","print(img.shape)\n","#x, y = img.shape[0:2]\n","# cv2.imshow('OriginalPicture', img)\n"," \n","img_test1 = cv2.resize(img, (int(img.shape[0] / 40), int(img.shape[1] / 40)))\n","print(img_test1.shape)\n","# cv2.imshow('resize0', img_test1)\n","\n","img = PIL.Image.open(\"F:/Tennis/prediction/frame_0.jpg\").convert(\"L\") # L = R * 299/1000 + G * 587/1000 + B * 114/1000 # (\"RGB\")\n","img = img.resize((20, 20))\n","img = img.save(\"F:/Tennis/prediction/frame_0_test.jpg\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**K-means**"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# from sklearn.cluster import KMeans\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n","# kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X, y)\n","# kmeans.labels_\n","# kmeans.predict([[0, 0], [12, 3]])\n","# kmeans.cluster_centers_\n","\n","# plt.scatter(X, y, c=kmeans.labels_)\n","# plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Arbre de décision**"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# from sklearn.datasets import load_iris\n","# from sklearn import tree\n","\n","# X, y = X.values, y.values\n","# clf = tree.DecisionTreeClassifier()\n","# clf = clf.fit(X, y)\n","\n","# tree.plot_tree(clf)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Réseaux de neurones**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T17:33:00.198694Z","iopub.status.busy":"2023-05-01T17:33:00.198055Z","iopub.status.idle":"2023-05-01T17:33:13.210244Z","shell.execute_reply":"2023-05-01T17:33:13.209050Z","shell.execute_reply.started":"2023-05-01T17:33:00.198654Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 16)                46096     \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                544       \n","                                                                 \n"," dense_5 (Dense)             (None, 3)                 99        \n","                                                                 \n","=================================================================\n","Total params: 46,739\n","Trainable params: 46,739\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Construction du model avec tensorflow\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import tensorflow as tf\n","\n","model = Sequential(\n","    [               \n","        tf.keras.Input(shape = 2880), # 16*12 * 15 = 2880\n","        Dense(units=16, activation=\"sigmoid\"),\n","        Dense(units=32, activation=\"sigmoid\"),\n","        Dense(units=3, activation=\"softmax\"),\n","    ]\n",")          \n","model.summary()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T17:33:13.225244Z","iopub.status.busy":"2023-05-01T17:33:13.224682Z","iopub.status.idle":"2023-05-01T17:34:13.911133Z","shell.execute_reply":"2023-05-01T17:34:13.910061Z","shell.execute_reply.started":"2023-05-01T17:33:13.225203Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.1417 - accuracy: 0.3356\n","Epoch 2/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0949 - accuracy: 0.3644\n","Epoch 3/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0899 - accuracy: 0.3778\n","Epoch 4/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0877 - accuracy: 0.3933\n","Epoch 5/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0841 - accuracy: 0.3800\n","Epoch 6/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0762 - accuracy: 0.4422\n","Epoch 7/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0764 - accuracy: 0.4178\n","Epoch 8/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0895 - accuracy: 0.3711\n","Epoch 9/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0843 - accuracy: 0.4111\n","Epoch 10/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0780 - accuracy: 0.4267\n","Epoch 11/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0675 - accuracy: 0.4778\n","Epoch 12/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0675 - accuracy: 0.4533\n","Epoch 13/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 1.0638 - accuracy: 0.4867\n","Epoch 14/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0602 - accuracy: 0.4333\n","Epoch 15/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 1.0560 - accuracy: 0.5111\n","Epoch 16/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0499 - accuracy: 0.5200\n","Epoch 17/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 1.0498 - accuracy: 0.4822\n","Epoch 18/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0375 - accuracy: 0.5067\n","Epoch 19/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0328 - accuracy: 0.4644\n","Epoch 20/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0349 - accuracy: 0.5111\n","Epoch 21/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0237 - accuracy: 0.5178\n","Epoch 22/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0166 - accuracy: 0.5289\n","Epoch 23/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0289 - accuracy: 0.4978\n","Epoch 24/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 1.0304 - accuracy: 0.5067\n","Epoch 25/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0288 - accuracy: 0.4578\n","Epoch 26/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0175 - accuracy: 0.5000\n","Epoch 27/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0033 - accuracy: 0.5333\n","Epoch 28/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0000 - accuracy: 0.5711\n","Epoch 29/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0495 - accuracy: 0.4378\n","Epoch 30/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0353 - accuracy: 0.4578\n","Epoch 31/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0153 - accuracy: 0.5489\n","Epoch 32/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0035 - accuracy: 0.5356\n","Epoch 33/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 1.0018 - accuracy: 0.5244\n","Epoch 34/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9958 - accuracy: 0.5556\n","Epoch 35/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9889 - accuracy: 0.5400\n","Epoch 36/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9821 - accuracy: 0.5733\n","Epoch 37/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9610 - accuracy: 0.6311\n","Epoch 38/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9567 - accuracy: 0.6089\n","Epoch 39/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9563 - accuracy: 0.6489\n","Epoch 40/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9483 - accuracy: 0.6489\n","Epoch 41/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9413 - accuracy: 0.6733\n","Epoch 42/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9294 - accuracy: 0.6800\n","Epoch 43/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9206 - accuracy: 0.6378\n","Epoch 44/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.9246 - accuracy: 0.6289\n","Epoch 45/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.9321 - accuracy: 0.5622\n","Epoch 46/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.9279 - accuracy: 0.5822\n","Epoch 47/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8858 - accuracy: 0.6333\n","Epoch 48/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8639 - accuracy: 0.6289\n","Epoch 49/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8741 - accuracy: 0.6422\n","Epoch 50/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8987 - accuracy: 0.6067\n","Epoch 51/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8639 - accuracy: 0.6911\n","Epoch 52/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8459 - accuracy: 0.7044\n","Epoch 53/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8438 - accuracy: 0.6978\n","Epoch 54/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8409 - accuracy: 0.6889\n","Epoch 55/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8199 - accuracy: 0.7489\n","Epoch 56/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8829 - accuracy: 0.6933\n","Epoch 57/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8383 - accuracy: 0.6800\n","Epoch 58/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.6067\n","Epoch 59/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.8182 - accuracy: 0.6200\n","Epoch 60/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.8177 - accuracy: 0.6778\n","Epoch 61/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7965 - accuracy: 0.7244\n","Epoch 62/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7883 - accuracy: 0.7444\n","Epoch 63/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.7727 - accuracy: 0.7644\n","Epoch 64/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7559 - accuracy: 0.7800\n","Epoch 65/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7682 - accuracy: 0.7644\n","Epoch 66/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.7511\n","Epoch 67/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.7778\n","Epoch 68/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.8089\n","Epoch 69/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.8267\n","Epoch 70/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.8111\n","Epoch 71/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.7933\n","Epoch 72/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.7244\n","Epoch 73/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.7111\n","Epoch 74/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.6511\n","Epoch 75/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7829 - accuracy: 0.6956\n","Epoch 76/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7798 - accuracy: 0.6756\n","Epoch 77/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7640 - accuracy: 0.6578\n","Epoch 78/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7512 - accuracy: 0.6533\n","Epoch 79/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6644\n","Epoch 80/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.6978\n","Epoch 81/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.7222\n","Epoch 82/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.7511\n","Epoch 83/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.7244\n","Epoch 84/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.8156\n","Epoch 85/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.8133\n","Epoch 86/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.7911\n","Epoch 87/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.7622\n","Epoch 88/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.8178\n","Epoch 89/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.8378\n","Epoch 90/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.8444\n","Epoch 91/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.8511\n","Epoch 92/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7598 - accuracy: 0.6311\n","Epoch 93/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6422\n","Epoch 94/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.7111\n","Epoch 95/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.7311\n","Epoch 96/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.7622\n","Epoch 97/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.8022\n","Epoch 98/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.8244\n","Epoch 99/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.8356\n","Epoch 100/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.8311\n","Epoch 101/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8422\n","Epoch 102/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.8578\n","Epoch 103/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8600\n","Epoch 104/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.8489\n","Epoch 105/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.8244\n","Epoch 106/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.8067\n","Epoch 107/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.8022\n","Epoch 108/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.8022\n","Epoch 109/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.8022\n","Epoch 110/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.8022\n","Epoch 111/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.8022\n","Epoch 112/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.8022\n","Epoch 113/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.8022\n","Epoch 114/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.8022\n","Epoch 115/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.8022\n","Epoch 116/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.8022\n","Epoch 117/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.8022\n","Epoch 118/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.8022\n","Epoch 119/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.8000\n","Epoch 120/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.8022\n","Epoch 121/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.8044\n","Epoch 122/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.8022\n","Epoch 123/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8022\n","Epoch 124/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.8022\n","Epoch 125/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8022\n","Epoch 126/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.8022\n","Epoch 127/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.8000\n","Epoch 128/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.8022\n","Epoch 129/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.8022\n","Epoch 130/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.8022\n","Epoch 131/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.8022\n","Epoch 132/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.8022\n","Epoch 133/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.8022\n","Epoch 134/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.8000\n","Epoch 135/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.8022\n","Epoch 136/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.8022\n","Epoch 137/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.8022\n","Epoch 138/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8022\n","Epoch 139/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8000\n","Epoch 140/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.8022\n","Epoch 141/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.8022\n","Epoch 142/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.8022\n","Epoch 143/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.8022\n","Epoch 144/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.8022\n","Epoch 145/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8022\n","Epoch 146/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.8022\n","Epoch 147/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.8022\n","Epoch 148/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8022\n","Epoch 149/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.8044\n","Epoch 150/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8022\n","Epoch 151/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.8022\n","Epoch 152/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.8022\n","Epoch 153/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.8022\n","Epoch 154/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.8022\n","Epoch 155/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8022\n","Epoch 156/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8022\n","Epoch 157/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.8022\n","Epoch 158/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8022\n","Epoch 159/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8022\n","Epoch 160/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.8022\n","Epoch 161/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.8022\n","Epoch 162/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.8022\n","Epoch 163/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.8022\n","Epoch 164/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.8022\n","Epoch 165/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8022\n","Epoch 166/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.8022\n","Epoch 167/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.8022\n","Epoch 168/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.8022\n","Epoch 169/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.8022\n","Epoch 170/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8022\n","Epoch 171/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.8022\n","Epoch 172/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8022\n","Epoch 173/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.8022\n","Epoch 174/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.8022\n","Epoch 175/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.8022\n","Epoch 176/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.8022\n","Epoch 177/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.8022\n","Epoch 178/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.8022\n","Epoch 179/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7933\n","Epoch 180/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8244\n","Epoch 181/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.8400\n","Epoch 182/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.8311\n","Epoch 183/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.8400\n","Epoch 184/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.8600\n","Epoch 185/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8311\n","Epoch 186/1000\n","15/15 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7911\n","Epoch 187/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.8067\n","Epoch 188/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.8244\n","Epoch 189/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.8533\n","Epoch 190/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.8533\n","Epoch 191/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8556\n","Epoch 192/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8600\n","Epoch 193/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8644\n","Epoch 194/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8667\n","Epoch 195/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8556\n","Epoch 196/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8533\n","Epoch 197/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.8467\n","Epoch 198/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.8578\n","Epoch 199/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.8244\n","Epoch 200/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.8333\n","Epoch 201/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.8311\n","Epoch 202/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.8511\n","Epoch 203/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8467\n","Epoch 204/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.8556\n","Epoch 205/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.8556\n","Epoch 206/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8578\n","Epoch 207/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.8467\n","Epoch 208/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.8556\n","Epoch 209/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.8644\n","Epoch 210/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8400\n","Epoch 211/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.8244\n","Epoch 212/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.8178\n","Epoch 213/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.8311\n","Epoch 214/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8444\n","Epoch 215/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.8489\n","Epoch 216/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.8444\n","Epoch 217/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8600\n","Epoch 218/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8667\n","Epoch 219/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8689\n","Epoch 220/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8644\n","Epoch 221/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8556\n","Epoch 222/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8578\n","Epoch 223/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8600\n","Epoch 224/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.8689\n","Epoch 225/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8667\n","Epoch 226/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8644\n","Epoch 227/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8622\n","Epoch 228/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8489\n","Epoch 229/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8378\n","Epoch 230/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.8622\n","Epoch 231/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8733\n","Epoch 232/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.8667\n","Epoch 233/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.8689\n","Epoch 234/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8689\n","Epoch 235/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8689\n","Epoch 236/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8689\n","Epoch 237/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8689\n","Epoch 238/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8689\n","Epoch 239/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8689\n","Epoch 240/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8689\n","Epoch 241/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.8689\n","Epoch 242/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8689\n","Epoch 243/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.8689\n","Epoch 244/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.8689\n","Epoch 245/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8689\n","Epoch 246/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.8689\n","Epoch 247/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8689\n","Epoch 248/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8689\n","Epoch 249/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8689\n","Epoch 250/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.8689\n","Epoch 251/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8689\n","Epoch 252/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8689\n","Epoch 253/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8689\n","Epoch 254/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8689\n","Epoch 255/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8689\n","Epoch 256/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8689\n","Epoch 257/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8689\n","Epoch 258/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8689\n","Epoch 259/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.8689\n","Epoch 260/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8689\n","Epoch 261/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8689\n","Epoch 262/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.8689\n","Epoch 263/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8689\n","Epoch 264/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8689\n","Epoch 265/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8689\n","Epoch 266/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8689\n","Epoch 267/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8689\n","Epoch 268/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8689\n","Epoch 269/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8689\n","Epoch 270/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8689\n","Epoch 271/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8689\n","Epoch 272/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8689\n","Epoch 273/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8689\n","Epoch 274/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8689\n","Epoch 275/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8689\n","Epoch 276/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8689\n","Epoch 277/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8689\n","Epoch 278/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8689\n","Epoch 279/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8689\n","Epoch 280/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8689\n","Epoch 281/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8689\n","Epoch 282/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8689\n","Epoch 283/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8689\n","Epoch 284/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8689\n","Epoch 285/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.8689\n","Epoch 286/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.8689\n","Epoch 287/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8689\n","Epoch 288/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8689\n","Epoch 289/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8689\n","Epoch 290/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8689\n","Epoch 291/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8689\n","Epoch 292/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8689\n","Epoch 293/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8689\n","Epoch 294/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8689\n","Epoch 295/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8689\n","Epoch 296/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8689\n","Epoch 297/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8689\n","Epoch 298/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8689\n","Epoch 299/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8689\n","Epoch 300/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8689\n","Epoch 301/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8689\n","Epoch 302/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8689\n","Epoch 303/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8689\n","Epoch 304/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8689\n","Epoch 305/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8689\n","Epoch 306/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8689\n","Epoch 307/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8689\n","Epoch 308/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8689\n","Epoch 309/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.8689\n","Epoch 310/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8689\n","Epoch 311/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8689\n","Epoch 312/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.8622\n","Epoch 313/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8644\n","Epoch 314/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.8667\n","Epoch 315/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8622\n","Epoch 316/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.8422\n","Epoch 317/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8400\n","Epoch 318/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8400\n","Epoch 319/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.8667\n","Epoch 320/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.8244\n","Epoch 321/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.8444\n","Epoch 322/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8644\n","Epoch 323/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8556\n","Epoch 324/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.8644\n","Epoch 325/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.8733\n","Epoch 326/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8711\n","Epoch 327/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8733\n","Epoch 328/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8733\n","Epoch 329/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8733\n","Epoch 330/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.8733\n","Epoch 331/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8733\n","Epoch 332/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8733\n","Epoch 333/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8733\n","Epoch 334/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.8733\n","Epoch 335/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8733\n","Epoch 336/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8711\n","Epoch 337/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.8733\n","Epoch 338/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8733\n","Epoch 339/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.8733\n","Epoch 340/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8733\n","Epoch 341/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8733\n","Epoch 342/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.8733\n","Epoch 343/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8733\n","Epoch 344/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8733\n","Epoch 345/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8733\n","Epoch 346/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8711\n","Epoch 347/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.8756\n","Epoch 348/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8733\n","Epoch 349/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.8733\n","Epoch 350/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.8733\n","Epoch 351/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8733\n","Epoch 352/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.8733\n","Epoch 353/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8733\n","Epoch 354/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8733\n","Epoch 355/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8733\n","Epoch 356/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.8733\n","Epoch 357/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8733\n","Epoch 358/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8756\n","Epoch 359/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8733\n","Epoch 360/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8733\n","Epoch 361/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8733\n","Epoch 362/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8711\n","Epoch 363/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8733\n","Epoch 364/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8733\n","Epoch 365/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8733\n","Epoch 366/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8733\n","Epoch 367/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8733\n","Epoch 368/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8733\n","Epoch 369/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8756\n","Epoch 370/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8756\n","Epoch 371/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8733\n","Epoch 372/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8756\n","Epoch 373/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8733\n","Epoch 374/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8733\n","Epoch 375/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8733\n","Epoch 376/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8644\n","Epoch 377/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.8644\n","Epoch 378/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8644\n","Epoch 379/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.8644\n","Epoch 380/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.8644\n","Epoch 381/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.8644\n","Epoch 382/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.7978\n","Epoch 383/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.8400\n","Epoch 384/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.8133\n","Epoch 385/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.8111\n","Epoch 386/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7844\n","Epoch 387/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7778\n","Epoch 388/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7622\n","Epoch 389/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7404 - accuracy: 0.6378\n","Epoch 390/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.6511\n","Epoch 391/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.6578\n","Epoch 392/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.7111\n","Epoch 393/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.7044\n","Epoch 394/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.7289\n","Epoch 395/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.8200\n","Epoch 396/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.7933\n","Epoch 397/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.7800\n","Epoch 398/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.7933\n","Epoch 399/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.8067\n","Epoch 400/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.8244\n","Epoch 401/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.7133\n","Epoch 402/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7529 - accuracy: 0.6733\n","Epoch 403/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.7422\n","Epoch 404/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.7133\n","Epoch 405/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6911\n","Epoch 406/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.7244\n","Epoch 407/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.8089\n","Epoch 408/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7911\n","Epoch 409/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7867\n","Epoch 410/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7978\n","Epoch 411/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.8178\n","Epoch 412/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.8222\n","Epoch 413/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8244\n","Epoch 414/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.8267\n","Epoch 415/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.8289\n","Epoch 416/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8422\n","Epoch 417/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.8222\n","Epoch 418/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.8333\n","Epoch 419/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.8044\n","Epoch 420/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.8133\n","Epoch 421/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8378\n","Epoch 422/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8378\n","Epoch 423/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8400\n","Epoch 424/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8489\n","Epoch 425/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8333\n","Epoch 426/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7756\n","Epoch 427/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.8378\n","Epoch 428/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.8356\n","Epoch 429/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8400\n","Epoch 430/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.8644\n","Epoch 431/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8711\n","Epoch 432/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8733\n","Epoch 433/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.8689\n","Epoch 434/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.8689\n","Epoch 435/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8711\n","Epoch 436/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8711\n","Epoch 437/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.8689\n","Epoch 438/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.8689\n","Epoch 439/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.8578\n","Epoch 440/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.8289\n","Epoch 441/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8578\n","Epoch 442/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.8489\n","Epoch 443/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.8422\n","Epoch 444/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.8400\n","Epoch 445/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.8244\n","Epoch 446/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.8244\n","Epoch 447/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.8156\n","Epoch 448/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.8222\n","Epoch 449/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.8200\n","Epoch 450/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.8422\n","Epoch 451/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.8422\n","Epoch 452/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8444\n","Epoch 453/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8489\n","Epoch 454/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.8444\n","Epoch 455/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8467\n","Epoch 456/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8578\n","Epoch 457/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8489\n","Epoch 458/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8489\n","Epoch 459/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.8489\n","Epoch 460/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8489\n","Epoch 461/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8489\n","Epoch 462/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8489\n","Epoch 463/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8489\n","Epoch 464/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8489\n","Epoch 465/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.8489\n","Epoch 466/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.8489\n","Epoch 467/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.8467\n","Epoch 468/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.8444\n","Epoch 469/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.8444\n","Epoch 470/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.8400\n","Epoch 471/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.8400\n","Epoch 472/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8400\n","Epoch 473/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.8444\n","Epoch 474/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8444\n","Epoch 475/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8444\n","Epoch 476/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8556\n","Epoch 477/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8467\n","Epoch 478/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8489\n","Epoch 479/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8489\n","Epoch 480/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8467\n","Epoch 481/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8467\n","Epoch 482/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8467\n","Epoch 483/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8467\n","Epoch 484/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8467\n","Epoch 485/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.8467\n","Epoch 486/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8467\n","Epoch 487/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8467\n","Epoch 488/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8467\n","Epoch 489/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8467\n","Epoch 490/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8467\n","Epoch 491/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8467\n","Epoch 492/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8467\n","Epoch 493/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8467\n","Epoch 494/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8467\n","Epoch 495/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.8467\n","Epoch 496/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8467\n","Epoch 497/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8467\n","Epoch 498/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8467\n","Epoch 499/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8467\n","Epoch 500/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.8467\n","Epoch 501/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.8467\n","Epoch 502/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8467\n","Epoch 503/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8467\n","Epoch 504/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.8467\n","Epoch 505/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8467\n","Epoch 506/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8467\n","Epoch 507/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.8467\n","Epoch 508/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8467\n","Epoch 509/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8467\n","Epoch 510/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8467\n","Epoch 511/1000\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8467\n","Epoch 512/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8467\n","Epoch 513/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8467\n","Epoch 514/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8467\n","Epoch 515/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8467\n","Epoch 516/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8467\n","Epoch 517/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8467\n","Epoch 518/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.8467\n","Epoch 519/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8467\n","Epoch 520/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8467\n","Epoch 521/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.8467\n","Epoch 522/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.8467\n","Epoch 523/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8467\n","Epoch 524/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8467\n","Epoch 525/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.8467\n","Epoch 526/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8467\n","Epoch 527/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8467\n","Epoch 528/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8467\n","Epoch 529/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8467\n","Epoch 530/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8467\n","Epoch 531/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8467\n","Epoch 532/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8467\n","Epoch 533/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8467\n","Epoch 534/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8467\n","Epoch 535/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8467\n","Epoch 536/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8467\n","Epoch 537/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8467\n","Epoch 538/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8467\n","Epoch 539/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8467\n","Epoch 540/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8467\n","Epoch 541/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8467\n","Epoch 542/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8467\n","Epoch 543/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8467\n","Epoch 544/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8467\n","Epoch 545/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8467\n","Epoch 546/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8467\n","Epoch 547/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8467\n","Epoch 548/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8467\n","Epoch 549/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8467\n","Epoch 550/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8467\n","Epoch 551/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8467\n","Epoch 552/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8467\n","Epoch 553/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8467\n","Epoch 554/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8467\n","Epoch 555/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8467\n","Epoch 556/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8467\n","Epoch 557/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.8467\n","Epoch 558/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8467\n","Epoch 559/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8467\n","Epoch 560/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8467\n","Epoch 561/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8467\n","Epoch 562/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8467\n","Epoch 563/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8467\n","Epoch 564/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8467\n","Epoch 565/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8467\n","Epoch 566/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8467\n","Epoch 567/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8467\n","Epoch 568/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8467\n","Epoch 569/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8467\n","Epoch 570/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8467\n","Epoch 571/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.8467\n","Epoch 572/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8467\n","Epoch 573/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8467\n","Epoch 574/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8467\n","Epoch 575/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8467\n","Epoch 576/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8467\n","Epoch 577/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8467\n","Epoch 578/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8467\n","Epoch 579/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8467\n","Epoch 580/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.8467\n","Epoch 581/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8467\n","Epoch 582/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8467\n","Epoch 583/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8467\n","Epoch 584/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8467\n","Epoch 585/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8467\n","Epoch 586/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8467\n","Epoch 587/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8467\n","Epoch 588/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8489\n","Epoch 589/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8511\n","Epoch 590/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8511\n","Epoch 591/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8511\n","Epoch 592/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8511\n","Epoch 593/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8511\n","Epoch 594/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.8511\n","Epoch 595/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8533\n","Epoch 596/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.8556\n","Epoch 597/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.8556\n","Epoch 598/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8578\n","Epoch 599/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.8600\n","Epoch 600/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8622\n","Epoch 601/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8533\n","Epoch 602/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.8489\n","Epoch 603/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.8489\n","Epoch 604/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.8489\n","Epoch 605/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8489\n","Epoch 606/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.8489\n","Epoch 607/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.8489\n","Epoch 608/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.8489\n","Epoch 609/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.8489\n","Epoch 610/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8489\n","Epoch 611/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.8489\n","Epoch 612/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.8489\n","Epoch 613/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.8489\n","Epoch 614/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.8489\n","Epoch 615/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8489\n","Epoch 616/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.8489\n","Epoch 617/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8489\n","Epoch 618/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.8489\n","Epoch 619/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.8489\n","Epoch 620/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8489\n","Epoch 621/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.8489\n","Epoch 622/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8489\n","Epoch 623/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.8489\n","Epoch 624/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.8489\n","Epoch 625/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.8489\n","Epoch 626/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8489\n","Epoch 627/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.8489\n","Epoch 628/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.8489\n","Epoch 629/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8489\n","Epoch 630/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.8533\n","Epoch 631/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.8600\n","Epoch 632/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.8511\n","Epoch 633/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8489\n","Epoch 634/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.8600\n","Epoch 635/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.8533\n","Epoch 636/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.8333\n","Epoch 637/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.8356\n","Epoch 638/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8489\n","Epoch 639/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.8400\n","Epoch 640/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8467\n","Epoch 641/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8622\n","Epoch 642/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.8556\n","Epoch 643/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8578\n","Epoch 644/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8667\n","Epoch 645/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.8667\n","Epoch 646/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.8644\n","Epoch 647/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8667\n","Epoch 648/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.8667\n","Epoch 649/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.8667\n","Epoch 650/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8667\n","Epoch 651/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.8667\n","Epoch 652/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8667\n","Epoch 653/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8667\n","Epoch 654/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.8667\n","Epoch 655/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8667\n","Epoch 656/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.8667\n","Epoch 657/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.8667\n","Epoch 658/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.8667\n","Epoch 659/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 660/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 661/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8667\n","Epoch 662/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8667\n","Epoch 663/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8667\n","Epoch 664/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8667\n","Epoch 665/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8667\n","Epoch 666/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8667\n","Epoch 667/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8667\n","Epoch 668/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8667\n","Epoch 669/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8667\n","Epoch 670/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 671/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 672/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8667\n","Epoch 673/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8667\n","Epoch 674/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8667\n","Epoch 675/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 676/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8667\n","Epoch 677/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 678/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8667\n","Epoch 679/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.8667\n","Epoch 680/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 681/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 682/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 683/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8667\n","Epoch 684/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8667\n","Epoch 685/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 686/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 687/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.8667\n","Epoch 688/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.8667\n","Epoch 689/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8667\n","Epoch 690/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.8667\n","Epoch 691/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.8667\n","Epoch 692/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.8667\n","Epoch 693/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8667\n","Epoch 694/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8667\n","Epoch 695/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8667\n","Epoch 696/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.8667\n","Epoch 697/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8644\n","Epoch 698/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.8644\n","Epoch 699/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8644\n","Epoch 700/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8644\n","Epoch 701/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.8667\n","Epoch 702/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.8667\n","Epoch 703/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8667\n","Epoch 704/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8667\n","Epoch 705/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8667\n","Epoch 706/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.8667\n","Epoch 707/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8667\n","Epoch 708/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8667\n","Epoch 709/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8667\n","Epoch 710/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8667\n","Epoch 711/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 712/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.8667\n","Epoch 713/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8667\n","Epoch 714/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8667\n","Epoch 715/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 716/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 717/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8667\n","Epoch 718/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8667\n","Epoch 719/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8667\n","Epoch 720/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.8667\n","Epoch 721/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 722/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.8667\n","Epoch 723/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.8667\n","Epoch 724/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.8667\n","Epoch 725/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 726/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8667\n","Epoch 727/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 728/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8667\n","Epoch 729/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 730/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8667\n","Epoch 731/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8667\n","Epoch 732/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8667\n","Epoch 733/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8667\n","Epoch 734/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 735/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 736/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 737/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8667\n","Epoch 738/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8667\n","Epoch 739/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8667\n","Epoch 740/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8667\n","Epoch 741/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.8667\n","Epoch 742/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 743/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8667\n","Epoch 744/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8667\n","Epoch 745/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8667\n","Epoch 746/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8667\n","Epoch 747/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.8667\n","Epoch 748/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.8667\n","Epoch 749/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8667\n","Epoch 750/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8667\n","Epoch 751/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8667\n","Epoch 752/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8667\n","Epoch 753/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8667\n","Epoch 754/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 755/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8667\n","Epoch 756/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 757/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 758/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8667\n","Epoch 759/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 760/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8667\n","Epoch 761/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8667\n","Epoch 762/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 763/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8667\n","Epoch 764/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8667\n","Epoch 765/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8667\n","Epoch 766/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8667\n","Epoch 767/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 768/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8667\n","Epoch 769/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.8667\n","Epoch 770/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8667\n","Epoch 771/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8667\n","Epoch 772/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8667\n","Epoch 773/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 774/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.8667\n","Epoch 775/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 776/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.8667\n","Epoch 777/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 778/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 779/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8667\n","Epoch 780/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 781/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 782/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 783/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 784/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 785/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8667\n","Epoch 786/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8667\n","Epoch 787/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8667\n","Epoch 788/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8667\n","Epoch 789/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8667\n","Epoch 790/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 791/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8667\n","Epoch 792/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8667\n","Epoch 793/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.8667\n","Epoch 794/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8667\n","Epoch 795/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8667\n","Epoch 796/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8667\n","Epoch 797/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8667\n","Epoch 798/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8667\n","Epoch 799/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 800/1000\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.8667\n","Epoch 801/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 802/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8667\n","Epoch 803/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8667\n","Epoch 804/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8667\n","Epoch 805/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.8667\n","Epoch 806/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8667\n","Epoch 807/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.8667\n","Epoch 808/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.8667\n","Epoch 809/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8667\n","Epoch 810/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8667\n","Epoch 811/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8667\n","Epoch 812/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.8667\n","Epoch 813/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8667\n","Epoch 814/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.8667\n","Epoch 815/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8667\n","Epoch 816/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 817/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8667\n","Epoch 818/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8667\n","Epoch 819/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 820/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8667\n","Epoch 821/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8667\n","Epoch 822/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8667\n","Epoch 823/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8667\n","Epoch 824/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.8667\n","Epoch 825/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.8667\n","Epoch 826/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8667\n","Epoch 827/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8667\n","Epoch 828/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8667\n","Epoch 829/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8667\n","Epoch 830/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8667\n","Epoch 831/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8644\n","Epoch 832/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8667\n","Epoch 833/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8667\n","Epoch 834/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8667\n","Epoch 835/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8667\n","Epoch 836/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8667\n","Epoch 837/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8667\n","Epoch 838/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.8667\n","Epoch 839/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.8667\n","Epoch 840/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.8667\n","Epoch 841/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8667\n","Epoch 842/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 843/1000\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 844/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 845/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","Epoch 846/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 847/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8667\n","Epoch 848/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8667\n","Epoch 849/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8667\n","Epoch 850/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 851/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.8667\n","Epoch 852/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 853/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 854/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.8667\n","Epoch 855/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8667\n","Epoch 856/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 857/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8667\n","Epoch 858/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8667\n","Epoch 859/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8667\n","Epoch 860/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 861/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 862/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8667\n","Epoch 863/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8667\n","Epoch 864/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8667\n","Epoch 865/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8667\n","Epoch 866/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 867/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 868/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8667\n","Epoch 869/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.8667\n","Epoch 870/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.8667\n","Epoch 871/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8667\n","Epoch 872/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8667\n","Epoch 873/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8667\n","Epoch 874/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 875/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.8667\n","Epoch 876/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8667\n","Epoch 877/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.8667\n","Epoch 878/1000\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8667\n","Epoch 879/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8667\n","Epoch 880/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8667\n","Epoch 881/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 882/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 883/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8667\n","Epoch 884/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8667\n","Epoch 885/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 886/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8667\n","Epoch 887/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8667\n","Epoch 888/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.8667\n","Epoch 889/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8667\n","Epoch 890/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.8667\n","Epoch 891/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.8667\n","Epoch 892/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 893/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8667\n","Epoch 894/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 895/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 896/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 897/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8667\n","Epoch 898/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8667\n","Epoch 899/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.8667\n","Epoch 900/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8667\n","Epoch 901/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8667\n","Epoch 902/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8667\n","Epoch 903/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 904/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8667\n","Epoch 905/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 906/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8667\n","Epoch 907/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 908/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","Epoch 909/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 910/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.8667\n","Epoch 911/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8667\n","Epoch 912/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8667\n","Epoch 913/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.8667\n","Epoch 914/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8667\n","Epoch 915/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 916/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 917/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8667\n","Epoch 918/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8667\n","Epoch 919/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8667\n","Epoch 920/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8667\n","Epoch 921/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 922/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 923/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 924/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8667\n","Epoch 925/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8667\n","Epoch 926/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8667\n","Epoch 927/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.8667\n","Epoch 928/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 929/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8667\n","Epoch 930/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8667\n","Epoch 931/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8667\n","Epoch 932/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8667\n","Epoch 933/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8667\n","Epoch 934/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 935/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8667\n","Epoch 936/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.8667\n","Epoch 937/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.8667\n","Epoch 938/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8667\n","Epoch 939/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 940/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 941/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8667\n","Epoch 942/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.8667\n","Epoch 943/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8667\n","Epoch 944/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.8667\n","Epoch 945/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.8667\n","Epoch 946/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 947/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.8667\n","Epoch 948/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8667\n","Epoch 949/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8667\n","Epoch 950/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 951/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8667\n","Epoch 952/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8667\n","Epoch 953/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","Epoch 954/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 955/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 956/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8667\n","Epoch 957/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 958/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8667\n","Epoch 959/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.8667\n","Epoch 960/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8667\n","Epoch 961/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.8667\n","Epoch 962/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 963/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8667\n","Epoch 964/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8667\n","Epoch 965/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 966/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 967/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.8667\n","Epoch 968/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 969/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 970/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8667\n","Epoch 971/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8667\n","Epoch 972/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8667\n","Epoch 973/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 974/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 975/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.8667\n","Epoch 976/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.8667\n","Epoch 977/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.8667\n","Epoch 978/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8667\n","Epoch 979/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 980/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 981/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8667\n","Epoch 982/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8667\n","Epoch 983/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8667\n","Epoch 984/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 985/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8667\n","Epoch 986/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","Epoch 987/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8667\n","Epoch 988/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8667\n","Epoch 989/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","Epoch 990/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8667\n","Epoch 991/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.8667\n","Epoch 992/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8667\n","Epoch 993/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8667\n","Epoch 994/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8667\n","Epoch 995/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","Epoch 996/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.8667\n","Epoch 997/1000\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8667\n","Epoch 998/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.8667\n","Epoch 999/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8667\n","Epoch 1000/1000\n","15/15 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8667\n","1/1 [==============================] - 0s 47ms/step\n","[[0.12064935 0.81949145 0.05985921]\n"," [0.78089756 0.01100029 0.20810217]\n"," [0.78089875 0.01100035 0.20810093]\n"," [0.88106525 0.10533452 0.01360023]\n"," [0.12064935 0.81949145 0.05985921]\n"," [0.0435697  0.05683058 0.89959973]\n"," [0.12064935 0.81949145 0.05985921]\n"," [0.12064935 0.81949145 0.05985921]\n"," [0.12064935 0.81949145 0.05985921]\n"," [0.12064935 0.81949145 0.05985921]\n"," [0.0435697  0.05683058 0.89959973]\n"," [0.0435697  0.05683058 0.89959973]\n"," [0.0435697  0.05683056 0.89959973]\n"," [0.0435697  0.05683056 0.89959973]\n"," [0.0435697  0.05683056 0.89959973]]\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import tensorflow as tf\n","\n","model.compile(\n","    #optimizer = 'RMSprop', loss = 'categorical_crossentropy', metrics = ['acc']\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # 'sparse_categorical_crossentropy',\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), # 'Adam',\n","    metrics=['accuracy']\n",")\n","\n","history = model.fit(\n","    X, y,\n","    epochs = 1000,\n","    # batch_size = 32 # données transmises pour une session\n",")\n","\n","prediction = model.predict(X_test) # np.expand_dims(X_test, axis = 1)\n","# prediction_p = tf.nn.softmax(prediction)\n","# yhat = np.argmax(prediction)\n","print (prediction)\n","\n","# Softmax\n","# def softmax(z):  \n","#     ez = np.exp(z)\n","#     a = ez/np.sum(ez)\n","#     return a\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8]\n","# [4, 0, 0, 0, 4, 8, 4, 0, 4, 4, 8, 8, 8, 8, 8]\n","# 12/15"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Réseau neuronal convolutif**"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 10, 254, 32)       896       \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 10, 254, 32)      128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 5, 127, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 5, 127, 32)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 3, 125, 64)        18496     \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 3, 125, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 1, 62, 64)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 1, 62, 64)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 3968)              0         \n","                                                                 \n"," dense_7 (Dense)             (None, 3)                 11907     \n","                                                                 \n","=================================================================\n","Total params: 31,683\n","Trainable params: 31,491\n","Non-trainable params: 192\n","_________________________________________________________________\n"]}],"source":["# contruction du modèle\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","\n","model_cnn = Sequential(\n","    [\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(12, 256, 3)),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","        \n","        Conv2D(64, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","        \n","        # Conv2D(128, (3, 3), activation='relu'),\n","        # BatchNormalization(),\n","        # MaxPooling2D(pool_size=(2, 2)),\n","        # Dropout(0.25),\n","        \n","        Flatten(),\n","        # Dense(512, activation='relu'),\n","        # BatchNormalization(),\n","        # Dropout(0.5),\n","        Dense(3, activation='softmax')\n","    ]\n",")            \n","model_cnn.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","model_cnn.summary()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model_cnn\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     X_cnn, y,\n\u001b[0;32m      3\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test_cnn)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n","File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7gj3limy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"]}],"source":["history = model_cnn.fit(\n","    X_cnn, y,\n","    epochs = 1000,\n",")\n","prediction = model.predict(X_test_cnn)\n","print(prediction)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# N.B: Squelette"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:48:30.442267Z","iopub.status.busy":"2023-05-01T19:48:30.441422Z","iopub.status.idle":"2023-05-01T19:48:30.450620Z","shell.execute_reply":"2023-05-01T19:48:30.449466Z","shell.execute_reply.started":"2023-05-01T19:48:30.442224Z"},"trusted":true},"outputs":[],"source":["# Modèle général pour tester les paramètres\n","\n","# def neural_network(num_layer, units, learning_rate=0.01):\n","#     \"\"\"\n","#     Parameters\n","#     ----------\n","#     num_layer       : int\n","#                     number of layers\n","#     units           : list\n","#                     number of units in each layer\n","#     learning_rate   : float\n","#                     learning rate of the optimizer of the model\n","#     \"\"\"\n","#     if (len(units) != num_layer):\n","#         raise ValueError(\"Number of list of units must be equal to number of layers\")\n","#     model = Sequential()\n","#     model.add(Dense(units=units[0], input_dim=X_train.shape[1], activation=\"relu\"))\n","#     for i in range(1, num_layer-1):\n","#         model.add(Dense(units=units[i], activation=\"relu\"))\n","#     model.add(Dense(units=1, activation=\"linear\"))\n","#     model.compile(\n","#         loss=tf.keras.losses.MeanAbsoluteError(),\n","#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","#         metrics=[tf.keras.metrics.MeanAbsoluteError()]\n","#     )\n","#     return model"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:48:32.720192Z","iopub.status.busy":"2023-05-01T19:48:32.719109Z","iopub.status.idle":"2023-05-01T19:48:32.728809Z","shell.execute_reply":"2023-05-01T19:48:32.727670Z","shell.execute_reply.started":"2023-05-01T19:48:32.720135Z"},"trusted":true},"outputs":[],"source":["# Evaluation des modèle\n","\n","# histories_neural_network = []\n","# def neural_network_score(num_layer, units, learning_rate=[0.001, 0.01, 0.1]):\n","#     \"\"\"\n","#     Parameters\n","#     ----------\n","#     num_layer       : int\n","#                     number of layers\n","#     units           : list\n","#                     number of units in each layer\n","#     learning_rate   : list\n","#                     learning rate of the optimizer of the model\n","#     \"\"\"\n","#     if (len(units) != num_layer):\n","#         raise ValueError('Le nombre de couches doit être égale à la taille de la liste des neurones')\n","#     for i in range(len(learning_rate)):\n","#         model = neural_network(num_layer, units, learning_rate=learning_rate[i])\n","#         model.save(f\"neural_network_model_{i}.h5\")\n","#         history = model.fit(\n","#             X_train, y_train,\n","#             epochs=50,\n","#             batch_size=50,\n","#             validation_split=0.2\n","#         )\n","#         histories_neural_network.append(history)\n","#         y_pred = model.predict(X_test)\n","#         y_pred = np.reshape(y_pred, (y_pred.shape[0],))\n","#         print(f'TEST - R2 score avec le taux {learning_rate[i]} : {r2_score(y_test_numpy, y_pred)}')\n","#         print(f'TEST - MAE score avec le taux {learning_rate[i]} : {history.history[\"val_loss\"][-1]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:48:35.578176Z","iopub.status.busy":"2023-05-01T19:48:35.577549Z","iopub.status.idle":"2023-05-01T19:51:53.617320Z","shell.execute_reply":"2023-05-01T19:51:53.616033Z","shell.execute_reply.started":"2023-05-01T19:48:35.578139Z"},"trusted":true},"outputs":[],"source":["# Entraînement des différents modèles\n","\n","# num_layer = 4\n","# units = [128, 256, 256, 1]\n","# neural_network_score(num_layer, units)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:51:53.620030Z","iopub.status.busy":"2023-05-01T19:51:53.619615Z","iopub.status.idle":"2023-05-01T19:51:53.908437Z","shell.execute_reply":"2023-05-01T19:51:53.907328Z","shell.execute_reply.started":"2023-05-01T19:51:53.619967Z"},"trusted":true},"outputs":[],"source":["#Visualiser les traces\n","\n","# from sklearn.metrics import r2_score\n","# plt.plot(histories_neural_network[0].history['val_loss'])\n","# plt.plot(histories_neural_network[1].history['val_loss'])\n","# plt.plot(histories_neural_network[2].history['val_loss'])\n","# plt.title('Model loss')  \n","# plt.ylabel('Val Loss')  \n","# plt.xlabel('Epoch')  \n","# plt.legend(['taux = 0.001', 'taux = 0.01', 'taux = 0.1'], loc='upper right')  \n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T19:52:32.649675Z","iopub.status.busy":"2023-05-01T19:52:32.649288Z","iopub.status.idle":"2023-05-01T19:52:33.255224Z","shell.execute_reply":"2023-05-01T19:52:33.254240Z","shell.execute_reply.started":"2023-05-01T19:52:32.649642Z"},"trusted":true},"outputs":[],"source":["# Test de la performance\n","#from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","#from math import sqrt\n","\n","# X_test_numpy = np.array(X_test)\n","# y_test_numpy = np.array(y_test)\n","# y_pred = model.predict(X_test_numpy)\n","# y_pred = np.reshape(y_pred, (y_pred.shape[0],))\n","# plt.scatter(y_test, y_pred, color=\"b\")\n","# plt.plot(y_test, y_test, color=\"r\")\n","# r2_nn = r2_score(y_test_numpy, y_pred)\n","# print('TEST - R2 score - Réseau de neurones: ', r2_nn)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
